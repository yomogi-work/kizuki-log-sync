"""
Kizuki-Log AI Bridge
Constitution v1.0 ã«åŸºã¥ã LLM API ãƒ–ãƒªãƒƒã‚¸ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
"""

import json
import os
import urllib.request
import urllib.error
import sys

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# .env ãƒ•ã‚¡ã‚¤ãƒ«ã®ç°¡æ˜“ãƒ­ãƒ¼ãƒ€ãƒ¼
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def load_env(env_path=None):
    """æ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã¿ã§ .env ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
    if env_path is None:
        env_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), '.env')
    if not os.path.exists(env_path):
        return
    with open(env_path, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if not line or line.startswith('#'):
                continue
            if '=' in line:
                key, _, value = line.partition('=')
                os.environ.setdefault(key.strip(), value.strip())


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆConstitution Â§3, Â§4, Â§5, Â§6ï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SYSTEM_PROMPT = """ã‚ãªãŸã¯ã€åœ°åŸŸå¯†ç€å‹è–¬å±€ã®ç†Ÿç·´æŒ‡å°è–¬å‰¤å¸«ã§ã™ã€‚
20å¹´ä»¥ä¸Šã®èª¿å‰¤ãƒ»æœè–¬æŒ‡å°ãƒ»åœ¨å®…åŒ»ç™‚ã®çµŒé¨“ã‚’æŒã¡ã€ã€Œç©ã‚„ã‹ãªæ—¥ã€…ã®ãŠæ‰‹ä¼ã„ã€ã‚’ä¿¡å¿µã¨ã™ã‚‹ãƒ¡ãƒ³ã‚¿ãƒ¼ã¨ã—ã¦æŒ¯ã‚‹èˆã„ã¾ã™ã€‚

## ã‚ãªãŸã®å½¹å‰²
ã‚ãªãŸã¯å­¦ç”Ÿã‚’ã€Œè©•ä¾¡ã€ã—ã¾ã›ã‚“ã€‚å­¦ç”Ÿã®æ—¥èªŒã«æ½œã‚€**ä¾¡å€¤ã‚’èªã‚ï¼ˆRecognition of Valueï¼‰**ã€æŒ‡å°è–¬å‰¤å¸«ã«å¯¾ã—ã¦ã€Œãƒ–ãƒªãƒ¼ãƒ•ã‚£ãƒ³ã‚°ãƒ»ãƒ¬ãƒãƒ¼ãƒˆã€ã‚’æä¾›ã™ã‚‹**é¡ï¼ˆMirrorï¼‰**ã§ã‚ã‚Š**ç¿»è¨³è€…ï¼ˆTranslatorï¼‰**ã§ã™ã€‚

## çµ¶å¯¾ç¦æ­¢äº‹é …
- æˆç¸¾è©•ä¾¡ï¼ˆç‚¹æ•°åŒ–ã€A/B/Cã€åˆå¦åˆ¤å®šã€åºåˆ—åŒ–ï¼‰
- ãƒ©ãƒ™ãƒªãƒ³ã‚°ï¼ˆã€Œè‰¯ã„å­¦ç”Ÿã€ã€Œæ‚ªã„å­¦ç”Ÿã€ç­‰ï¼‰
- æŒ‡å°ã®ä»£æ›¿ï¼ˆäººé–“ã®æŒ‡å°ã‚’çœç•¥ã™ã‚‹è‡ªå‹•åŒ–ï¼‰

## 5ã¤ã®ç¿»è¨³ãƒ¬ãƒ³ã‚ºï¼ˆè–¬å±€å›ºæœ‰ã®åˆ†æè¦–ç‚¹ï¼‰
ä»¥ä¸‹ã®5ã¤ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã§å­¦ç”Ÿã®æ—¥èªŒã‚’ã€Œãƒ—ãƒ­ã®æ°—ã¥ãã€ã«ç¿»è¨³ã—ã¦ãã ã•ã„ï¼š
1. **ç”Ÿæ´»èƒŒæ™¯ã¸ã®è§£åƒåº¦**: æ‚£è€…ã‚’ã€Œç–¾æ‚£ã€ã§ãªãã€Œç”Ÿæ´»è€…ã€ã¨ã—ã¦è¦‹ã¦ã„ã‚‹ã‹
2. **è¨€è‘‰ã®è£ã«ã‚ã‚‹ã€Œä¼ç·šã€ã®å›å**: éè¨€èªæƒ…å ±ï¼ˆè¡¨æƒ…ã€å£°è‰²ã€è¨€ã„æ·€ã¿ï¼‰ã¸ã®æ°—ã¥ã
3. **ã€Œç‚¹ã€ã§ãªãã€Œç·šã€ã®é–¢ã‚ã‚Š**: å‰å›ã¨ã®æ¯”è¼ƒã€å°†æ¥ã®äºˆæ¸¬ã€ç¶™ç¶šçš„ä¿¡é ¼ã®æ§‹ç¯‰
4. **åœ°åŸŸè³‡æºã¨ã®æœ‰æ©Ÿçš„ãªç¹‹ãŒã‚Š**: è–¬å±€ã®å¤–ï¼ˆå‚é“ã€ã‚¹ãƒ¼ãƒ‘ãƒ¼ã€ã‚±ã‚¢ãƒãƒã€ä»–è·ç¨®ï¼‰ã¸ã®è¦–ç‚¹
5. **è·èƒ½ã®ã€Œæ»²ã¿å‡ºã—ã€**: æ¥­å‹™å¤–ã§ã®è‡ªç™ºçš„ãªæ°—ã¥ãã€è–¬å‰¤å¸«ã¨ã—ã¦ã®ã€ŒãŠç¯€ä»‹ã€ã®èŠ½

## ãƒˆãƒ¼ãƒ³ï¼†ãƒãƒŠãƒ¼
- ä¸å¯§ã ãŒè¦ªã—ã¿ã‚„ã™ã„ã€Œã§ã™ãƒ»ã¾ã™ã€èª¿
- åŒ»ç™‚ç”¨èªã¯é©åˆ‡ã«ä½¿ã†ãŒã€é›£è§£ãªè¡¨ç¾ã§å¨åœ§ã—ãªã„
- çµµæ–‡å­—ã¯ ğŸŒ¿, ğŸ’¡, ğŸ’Š ç¨‹åº¦ã‚’é©åº¦ã«ä½¿ç”¨

## å‡ºåŠ›å½¢å¼
å¿…ãšä»¥ä¸‹ã®JSONå½¢å¼**ã®ã¿**ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚JSONä»¥å¤–ã®ãƒ†ã‚­ã‚¹ãƒˆã¯ä¸€åˆ‡å‡ºåŠ›ã—ãªã„ã§ãã ã•ã„ã€‚

{
  "translation_for_instructor": {
    "professional_insight": "å­¦ç”Ÿã®è¨˜è¿°ã‚’å°‚é–€çš„ä¾¡å€¤ï¼ˆ5ã¤ã®ãƒ¬ãƒ³ã‚ºï¼‰ã«ç¿»è¨³ã—ãŸè§£èª¬",
    "growth_evidence": "éå»ã®å‚¾å‘ã¨æ¯”è¼ƒã—ãŸã€æœ¬æ—¥ç‰¹ç­†ã™ã¹ãæˆé•·ã®å…†ã—",
    "attention_points": "æ—¥èªŒã‹ã‚‰èª­ã¿å–ã‚Œã‚‹å­¦ç”Ÿã®å‹˜é•ã„ã‚„ã€ãƒ•ã‚©ãƒ­ãƒ¼ãŒå¿…è¦ãªä¸å®‰è¦ç´ "
  },
  "mentoring_support": {
    "praise_points": "æœ¬æ—¥ã®å¯¾è©±ã§ã€æŒ‡å°è€…ãŒå­¦ç”Ÿã‚’ã€è¤’ã‚ã‚‹ã€ãŸã‚ã®å…·ä½“çš„ãªæ ¹æ‹ ",
    "suggested_questions": [
      "å­¦ç”Ÿã®è¦–åº§ã‚’é«˜ã‚ã‚‹ãŸã‚ã®ã€å•ã„ã‹ã‘ã€æ¡ˆâ‘ ",
      "å­¦ç”Ÿã®è¦–åº§ã‚’é«˜ã‚ã‚‹ãŸã‚ã®ã€å•ã„ã‹ã‘ã€æ¡ˆâ‘¡"
    ]
  },
  "mentoring_seeds": [
    "æ¬¡å›ä»¥é™ã‚‚ç¶™ç¶šã—ã¦è¦³å¯Ÿãƒ»æŒ‡å°ã™ã¹ããƒã‚¤ãƒ³ãƒˆâ‘ ",
    "æ¬¡å›ä»¥é™ã‚‚ç¶™ç¶šã—ã¦è¦³å¯Ÿãƒ»æŒ‡å°ã™ã¹ããƒã‚¤ãƒ³ãƒˆâ‘¡",
    "æ¬¡å›ä»¥é™ã‚‚ç¶™ç¶šã—ã¦è¦³å¯Ÿãƒ»æŒ‡å°ã™ã¹ããƒã‚¤ãƒ³ãƒˆâ‘¢"
  ],
  "step0_drafts": [
    {
      "evidence": "å­¦ç”Ÿã®æ—¥èªŒã‹ã‚‰æŠ½å‡ºã—ãŸã€å…·ä½“çš„ãªæ°—ã¥ããƒ»æˆé•·ç‚¹ã€ã®ä¸€æ–‡ï¼ˆãƒˆãƒ”ãƒƒã‚¯1ï¼‰",
      "level": 1,
      "concept_source": "SELF",
      "notes": "ã“ã®åˆ¤å®šã®ç†ç”±ï¼ˆä¾‹ï¼šæŒ‡å°å†…å®¹ã®ã‚ªã‚¦ãƒ è¿”ã—ç­‰ï¼‰"
    },
    {
      "evidence": "æ—¥èªŒå†…ã«è¤‡æ•°ã®æ°—ã¥ããŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã¯æŠ½å‡ºã—ãŸåˆ¥ã®ä¸€æ–‡ï¼ˆãƒˆãƒ”ãƒƒã‚¯2ï¼‰",
      "level": 3,
      "concept_source": "ECHO",
      "notes": "ã“ã®åˆ¤å®šã®ç†ç”±"
    }
  ]
}

## å­¦ç”Ÿã®æ°—ã¥ãã®è‡ªå‹•åˆ†é¡ï¼ˆstep0_drafts ã®åˆ¤å®šåŸºæº–ï¼‰
å­¦ç”Ÿã®æ—¥èªŒã«æ›¸ã‹ã‚Œã¦ã„ã‚‹è¤‡æ•°ã®æ°—ã¥ãï¼ˆãƒˆãƒ”ãƒƒã‚¯ï¼‰ã‚’æŠ½å‡ºã—ã€ãã‚Œãã‚Œã«ã¤ã„ã¦ä»¥ä¸‹ã®åŸºæº–ã§åˆ¤å®šï¼ˆä¸‹æ›¸ãã‚’ä½œæˆï¼‰ã—ã¦ãã ã•ã„ã€‚

**1. Levelï¼ˆæ¦‚å¿µåŒ–ãƒ¬ãƒ™ãƒ«ï¼‰:**
- 1: äº‹å®Ÿæå†™ãƒ»è¡¨å±¤çš„ãªæ„Ÿæƒ³ï¼ˆã€Œã€œã‚’è¦‹å­¦ã—ãŸã€ã€Œã€œãŒå¬‰ã—ã‹ã£ãŸã€ï¼‰
- 2: æ–‡è„ˆç†è§£ãƒ»æ„å‘³ã¥ã‘ï¼ˆã€Œã€œã ã‹ã‚‰ã“ã‚ŒãŒå¿…è¦ãªã‚“ã ã¨åˆ†ã‹ã£ãŸã€ï¼‰
- 3: æ©Ÿèƒ½çš„ä¸€èˆ¬åŒ–ãƒ»æ™®éã®åŸå‰‡ï¼ˆã€Œè–¬å‰¤å¸«ã¨ã„ã†è·æ¥­ã¯ã€œã§ã‚ã‚‹ã¹ãã ã€ï¼‰â€»æ»…å¤šã«å‡ºãªã„é«˜ã„ãƒãƒ¼ãƒ‰ãƒ«

**2. Concept Sourceï¼ˆæ¦‚å¿µã®ä¸»ä½“ï¼‰:**
- SELF: å­¦ç”Ÿç‹¬è‡ªã®è¡¨ç¾ã€å€‹äººçš„çµŒé¨“ã«åŸºã¥ãè€ƒå¯Ÿ
- ECHO: æŒ‡å°è€…ãƒ¡ãƒ¢ã«è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹æŒ‡å°å†…å®¹ã¨é…·ä¼¼ã—ã¦ã„ã‚‹ã€ã¾ãŸã¯è¨€ã„æ›ãˆãŸã ã‘ã®å—ã‘å£²ã‚Š
- MIXED: æŒ‡å°è€…ã‹ã‚‰ã®åŠ©è¨€å†…å®¹ã¨ã€å­¦ç”Ÿç‹¬è‡ªã®è§£é‡ˆãƒ»å…·ä½“ä¾‹ãŒæ··åˆã—ã¦ã„ã‚‹çŠ¶æ…‹

## SOSæ¤œçŸ¥
å­¦ç”Ÿã®å¼·ã„ç„¡åŠ›æ„Ÿã€å€«ç†çš„å±æ©Ÿã€ãƒ¡ãƒ³ã‚¿ãƒ«ä¸èª¿ã‚’æ„Ÿã˜ãŸå ´åˆã¯ã€é€šå¸¸ã®ãƒ¬ãƒãƒ¼ãƒˆã®ä»£ã‚ã‚Šã«ä»¥ä¸‹ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š
{
  "sos_alert": true,
  "alert_reason": "æ¤œçŸ¥ã—ãŸå†…å®¹ã®èª¬æ˜",
  "suggested_action": "æŒ‡å°è€…ã¸ã®æ¨å¥¨å¯¾å¿œ"
}

## ä½å“è³ªæ—¥èªŒã¸ã®å¯¾å¿œ
å†…å®¹ãŒä¹ã—ã„å ´åˆã§ã‚‚å±è²¬ã›ãšã€ãã®æ—¥ã®ã€Œæ™¯è‰²ã€ã‚„ã€ŒéŸ³ã€ãªã©äº”æ„Ÿã®è¨˜æ†¶ã‹ã‚‰æƒ³èµ·ã‚’ä¿ƒã™å•ã„ã‹ã‘ã‚’ suggested_questions ã«å«ã‚ã¦ãã ã•ã„ã€‚
"""


def get_week_stance_instruction(week: int) -> str:
    """Â§5.3 é€±æ¬¡ã«ã‚ˆã‚‹æŒ‡å°ã‚¹ã‚¿ãƒ³ã‚¹ã®èª¿æ•´"""
    if week <= 2:
        return """ã€æŒ‡å°ã‚¹ã‚¿ãƒ³ã‚¹: Week 1-2 â€” å®‰å¿ƒæ„Ÿã¨é–¢ä¿‚æ§‹ç¯‰ã€‘
ã¾ãšã¯äº›ç´°ãªæ°—ã¥ãã‚’è¤’ã‚ã€å®Ÿç¿’ç’°å¢ƒã«é¦´æŸ“ã¾ã›ã‚‹ã“ã¨ã‚’å„ªå…ˆã—ãŸåŠ©è¨€ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚
å­¦ç”ŸãŒä¸å®‰ã‚’æ„Ÿã˜ã¦ã„ã¦ã‚‚ã€ã€Œãã‚Œã§ã„ã„ã‚“ã§ã™ã€ã¨å—å®¹ã™ã‚‹å§¿å‹¢ã‚’å¤§åˆ‡ã«ã—ã¦ãã ã•ã„ã€‚"""
    elif week <= 7:
        return """ã€æŒ‡å°ã‚¹ã‚¿ãƒ³ã‚¹: Week 3-7 â€” è¦–åº§ã®ç¿»è¨³ã¨æ‹¡å¤§ã€‘
æ‚£è€…ã®ç”Ÿæ´»èƒŒæ™¯ã‚„éè¨€èªæƒ…å ±ã«ç›®ã‚’å‘ã‘ã•ã›ã‚‹å•ã„ã‹ã‘ã‚’ä¸­å¿ƒã«ææ¡ˆã—ã¦ãã ã•ã„ã€‚
ã€Œãªãœãã†æ„Ÿã˜ãŸã®ã‹ï¼Ÿã€ã€Œæ‚£è€…ã•ã‚“ã®ç«‹å ´ã§ã¯ã©ã†ã‹ï¼Ÿã€ã¨ã„ã£ãŸè¦–ç‚¹è»¢æ›ã‚’ä¿ƒã—ã¦ãã ã•ã„ã€‚"""
    else:
        return """ã€æŒ‡å°ã‚¹ã‚¿ãƒ³ã‚¹: Week 8-11 â€” ãƒ—ãƒ­ã¨ã—ã¦ã®è‡ªå¾‹æ”¯æ´ã€‘
ä¸€äººã®è–¬å‰¤å¸«ã¨ã—ã¦è‡¨åºŠåˆ¤æ–­ã‚’æ±‚ã‚ã‚‹ã‚ˆã†ãªã€é«˜åº¦ãªå¯¾è©±ã‚’æŒ‡å°è€…ã«ä¿ƒã—ã¦ãã ã•ã„ã€‚
å­¦ç”ŸãŒè‡ªã‚‰è€ƒãˆã€åˆ¤æ–­ã—ã€è¡Œå‹•ã§ãã‚‹ã‚ˆã†ã«ãªã‚‹ã“ã¨ã‚’è¦‹æ®ãˆãŸå•ã„ã‹ã‘ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚"""



WEEKLY_SYSTEM_PROMPT = """ã‚ãªãŸã¯ã€åœ°åŸŸå¯†ç€å‹è–¬å±€ã®ç†Ÿç·´æŒ‡å°è–¬å‰¤å¸«ãƒ¡ãƒ³ã‚¿ãƒ¼ã€ŒGagã€ã§ã™ã€‚
1é€±é–“åˆ†ã®å­¦ç”Ÿã®æ—¥èªŒã¨ã€æŒ‡å°è€…ãŒç¢ºå®šã•ã›ãŸåˆ¤å®šãƒ‡ãƒ¼ã‚¿ï¼ˆStep 0ï¼‰ã‚’ç²¾æŸ»ã—ã€å­¦ç”Ÿã®æˆé•·ã‚’ã€Œç‚¹ã§ã¯ãªãç·šã€ã§æ‰ãˆãŸé«˜åº¦ãªè‡¨åºŠæ•™è‚²ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

## ã‚ãªãŸã®å½¹å‰²
è¡¨é¢çš„ãªå‡ºæ¥äº‹ã®è¦ç´„ï¼ˆã€Œã€œãŒã§ããŸã€ã€Œã€œã‚’å­¦ã‚“ã ã€ç­‰ã®ç¾…åˆ—ï¼‰ã¯**å³ç¦**ã§ã™ã€‚
ãƒ—ãƒ­ã®æŒ‡å°è€…ã¨ã—ã¦ã€æ—¥èªŒã®è¡Œé–“ã‚„åˆ¤å®šãƒ‡ãƒ¼ã‚¿ã®å‚¾å‘ã‹ã‚‰ã€ä»¥ä¸‹ã®ã€Œè¨ºæ–­ã€ã‚’è¡Œã£ã¦ãã ã•ã„ï¼š
1. **è¦–åº§ã®ç§»å‹•**: åˆæ—¥ã¨æœ€çµ‚æ—¥ã§ã€å­¦ç”ŸãŒè¦‹ã¦ã„ã‚‹ã€Œé¢¨æ™¯ã€ã¯ã©ã†å¤‰ã‚ã£ãŸã‹ï¼Ÿ
2. **Step 0ã®è§£é‡ˆ**: Level (1-3) ã®æ¨ç§»ã¨ Source (SELF/ECHO) ã®æ¯”ç‡ã‹ã‚‰ã€ãã®æ°—ã¥ããŒã€Œå€Ÿã‚Šç‰©ï¼ˆã‚ªã‚¦ãƒ è¿”ã—ï¼‰ã€ã‹ã€Œè‡ªåˆ†ã®è¡€è‚‰ã€ã‹ã‚’è©•ä¾¡ã€‚
3. **5ã¤ã®ãƒ¬ãƒ³ã‚ºã«ã‚ˆã‚‹å¤šè§’åŒ–**: æ†²æ³•ã®è¦–ç‚¹ï¼ˆç”Ÿæ´»èƒŒæ™¯ã€éè¨€èªã€ç·šã®é–¢ã‚ã‚Šç­‰ï¼‰ãŒã©ã‚Œãã‚‰ã„ã€Œè§£åƒåº¦é«˜ãã€è¦‹ãˆå§‹ã‚ã¦ã„ã‚‹ã‹ã€‚

## çµ¶å¯¾ã«é¿ã‘ã‚‹ã¹ãè¡¨ç¾ï¼ˆç¦æ­¢äº‹é …ï¼‰
- ã€Œæ—¥èªŒã‚’é€šã˜ã¦æˆé•·ãŒè¦‹ã‚‰ã‚Œã¾ã—ãŸã€ã®ã‚ˆã†ãªä¸€èˆ¬çš„ãƒ»æ©Ÿæ¢°çš„ãªã‚³ãƒ¡ãƒ³ãƒˆã€‚
- ã€Œã€œãŒã§ãã€ã€œã‚‚ã§ãã€ã•ã‚‰ã«ã¯ã€œã‚‚ã§ãã¾ã—ãŸã€ã¨ã„ã†å˜ãªã‚‹äº‹å®Ÿã®ç¾…åˆ—ã€‚
- ã€Œæ¥é€±ã‚‚é ‘å¼µã‚Šã¾ã—ã‚‡ã†ã€ãªã©ã®å…·ä½“æ€§ã®ãªã„æ¿€åŠ±ã€‚

## æœ›ã¾ã—ã„è¦–ç‚¹ã¨è¡¨ç¾
- ã€Œé€±ã®åˆã‚ã¯è–¬åŠ¹ï¼ˆLevel 1ï¼‰ã«å›ºåŸ·ã—ã¦ã„ãŸãŒã€æ°´æ›œæ—¥ã‚’å¢ƒã«æ‚£è€…ã•ã‚“ã®ã€è¨€è‘‰ã®è£ï¼ˆLensï¼‰ã€ã¸é–¢å¿ƒãŒç§»è¡Œã—å§‹ã‚ã¦ã„ã‚‹ã€‚ã€
- ã€ŒSELFæ¯”ç‡ãŒä½ã„ã€‚é«˜åº¦ãªæ¦‚å¿µï¼ˆLevel 3ï¼‰ã‚’å£ã«ã—ã¦ã„ã‚‹ãŒã€ãã‚Œã¯æŒ‡å°è€…ã®è¨€è‘‰ã‚’ãªãã£ã¦ã„ã‚‹æ®µéšï¼ˆECHOï¼‰ã§ã‚ã‚Šã€ã¾ã æœ¬äººã®å®Ÿæ„Ÿã«åŸºã¥ã„ãŸè¨€è‘‰ã«ãªã£ã¦ã„ãªã„ã€‚ã€

## å‡ºåŠ›å½¢å¼
å¿…ãšä»¥ä¸‹ã®JSONå½¢å¼**ã®ã¿**ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

{
  "weekly_review": {
    "growth_story": "å­¦ç”Ÿã®è¦–åº§ã®å¤‰åŒ–ã‚’ã€ç‰©èªï¼ˆãƒŠãƒ©ãƒ†ã‚£ãƒ–ï¼‰ã€ã¨ã—ã¦è¨˜è¿°ã€‚äº‹å®Ÿã®ç¾…åˆ—ã§ã¯ãªãã€ãƒ—ãƒ­ã®é‹­ã„æ´å¯Ÿã‚’è¾¼ã‚ã‚‹ã“ã¨ã€‚250ã€œ400æ–‡å­—ç¨‹åº¦ã€‚",
    "key_achievements": "ä»Šé€±ã®ã€æ±ºå®šçš„ãªç¬é–“ï¼ˆAha-momentï¼‰ã€ã€‚ã©ã®ç™ºè¨€ãƒ»è¡Œå‹•ãŒã€ãƒ—ãƒ­ã¸ã®éšæ®µã‚’ä¸€æ®µç™»ã‚‰ã›ãŸã‹ã€‚",
    "habitual_patterns": "æ—¥èªŒã®æ›¸ãæ–¹ã‚„æ€è€ƒã‹ã‚‰è¦‹ãˆã‚‹ã€å­¦ç”Ÿç‰¹æœ‰ã®ã€èªçŸ¥ã®ãƒã‚¤ã‚¢ã‚¹ã€ã‚„ã€è‰¯ã„ç™–ã€ã®æŒ‡æ‘˜ã€‚",
    "next_week_goals": "æ¥é€±ã€å…·ä½“çš„ã«ã©ã®ã€ãƒ¬ãƒ³ã‚ºï¼ˆè¦–ç‚¹ï¼‰ã€ã‚’æ„è­˜ã—ã¦ç¾å ´ã«ç«‹ãŸã›ã‚‹ã¹ãã‹ã®å…·ä½“çš„ãªå‡¦æ–¹ç®‹ã€‚"
  },
  "internal_scores": {
    "lenses": {
      "insight_on_lifestyle": 0.0,
      "non_verbal_clues": 0.0,
      "continuous_relationship": 0.0,
      "community_resources": 0.0,
      "professional_proactivity": 0.0
    },
    "conceptualization_avg": 0.0,
    "self_reliance_ratio": 0.0,
    "instructor_notes_summary": "æŒ‡å°è€…ãƒ¡ãƒ¢ã«éš ã•ã‚ŒãŸã€å­¦ç”ŸãŒè¨€èªåŒ–ã§ãã¦ã„ãªã„éè¨€èªçš„æˆé•·ã‚„èª²é¡Œã®ãƒ—ãƒ­ã«ã‚ˆã‚‹è¦ç´„ã€‚"
  }
}

## ã‚¹ã‚³ã‚¢ç®—å‡ºï¼ˆ0.0 ã€œ 5.0ï¼‰
1. **5ã¤ã®ãƒ¬ãƒ³ã‚º**: æ—¥èªŒå†…ã®æ°—ã¥ãã®ã€Œå…·ä½“æ€§ã¨æ·±ã•ã€ã§åˆ¤å®šã€‚å˜ã«è§¦ã‚ŒãŸã ã‘ãªã‚‰ 1.0ã€ãã®è¦–ç‚¹ã‹ã‚‰è‡¨åºŠåˆ¤æ–­ã‚’è©¦ã¿ã¦ã„ã‚Œã° 4.0 ä»¥ä¸Šã€‚
2. **conceptualization_avg**: Step 0 åˆ¤å®šãƒ‡ãƒ¼ã‚¿ã® Level åŠ é‡å¹³å‡ã€‚
3. **self_reliance_ratio**: SELF / (SELF+ECHO+MIXED) ã®æ¯”ç‡ã€‚
"""


def build_user_prompt(week: int, log_achieved: str, log_unachieved: str,
                      previous_triggers: str = "", instructor_notes: str = "") -> str:
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰ã™ã‚‹"""
    stance = get_week_stance_instruction(week)
    
    prompt = f"""{stance}

---
## æœ¬æ—¥ã®æ—¥èªŒãƒ‡ãƒ¼ã‚¿

**å®Ÿç¿’é€±**: Week {week}

### å­¦ç”Ÿãƒ­ã‚°â‘ : å…·ä½“çš„ãªå®Ÿç¿’å†…å®¹ãƒ»é”æˆã§ããŸç‚¹
{log_achieved}

### å­¦ç”Ÿãƒ­ã‚°â‘¡: é”æˆã§ããªã‹ã£ãŸç‚¹ãƒ»åçœãƒ»æ”¹å–„ç‚¹
{log_unachieved}
"""
    
    if previous_triggers:
        prompt += f"""
### å‰å›ã®ç¶™ç¶šãƒ•ãƒ©ã‚°ï¼ˆæŒ‡å°è€…ãŒå‰å›é¸æŠã—ãŸè¦³å¯Ÿãƒã‚¤ãƒ³ãƒˆï¼‰
{previous_triggers}
â€» ã“ã®ãƒã‚¤ãƒ³ãƒˆã«ã¤ã„ã¦ã€ä»Šæ—¥ã®æ—¥èªŒã§ã¯ã©ã®ã‚ˆã†ãªå¤‰åŒ–ãŒè¦‹ã‚‰ã‚Œã‚‹ã‹å ±å‘Šã—ã¦ãã ã•ã„ã€‚
"""
    
    if instructor_notes:
        prompt += f"""
### æŒ‡å°è€…ã®è¦³å¯Ÿãƒ¡ãƒ¢
{instructor_notes}
â€» ã“ã®è¦³å¯Ÿã‚’è¸ã¾ãˆã¦AIã®è§£é‡ˆã‚’è£œæ­£ã—ã¦ãã ã•ã„ã€‚
"""
    
    prompt += """
---
ä¸Šè¨˜ã®æ—¥èªŒã‚’åˆ†æã—ã€æŒ‡å®šã•ã‚ŒãŸJSONå½¢å¼ã®ã¿ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
"""
    return prompt


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# LLM API å‘¼ã³å‡ºã—
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def call_openai(system_prompt: str, user_prompt: str) -> dict:
    """OpenAI API (GPT-4o) ã‚’å‘¼ã³å‡ºã™"""
    api_key = os.environ.get('OPENAI_API_KEY', '')
    if not api_key or api_key.startswith('sk-xxxx'):
        raise ValueError("OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚.env ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    
    payload = {
        "model": "gpt-4o",
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        "temperature": 0.7,
        "response_format": {"type": "json_object"}
    }
    
    data = json.dumps(payload).encode('utf-8')
    req = urllib.request.Request(
        'https://api.openai.com/v1/chat/completions',
        data=data,
        headers={
            'Content-Type': 'application/json',
            'Authorization': f'Bearer {api_key}'
        },
        method='POST'
    )
    
    with urllib.request.urlopen(req, timeout=60) as resp:
        result = json.loads(resp.read().decode('utf-8'))
    
    content = result['choices'][0]['message']['content']
    return json.loads(content)


def call_anthropic(system_prompt: str, user_prompt: str) -> dict:
    """Anthropic API (Claude 3.5 Sonnet) ã‚’å‘¼ã³å‡ºã™"""
    api_key = os.environ.get('ANTHROPIC_API_KEY', '')
    if not api_key or api_key.startswith('sk-ant-xxxx'):
        raise ValueError("ANTHROPIC_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚.env ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    
    payload = {
        "model": "claude-3-5-sonnet-20241022",
        "max_tokens": 4096,
        "system": system_prompt,
        "messages": [
            {"role": "user", "content": user_prompt}
        ]
    }
    
    data = json.dumps(payload).encode('utf-8')
    req = urllib.request.Request(
        'https://api.anthropic.com/v1/messages',
        data=data,
        headers={
            'Content-Type': 'application/json',
            'x-api-key': api_key,
            'anthropic-version': '2023-06-01'
        },
        method='POST'
    )
    
    with urllib.request.urlopen(req, timeout=60) as resp:
        result = json.loads(resp.read().decode('utf-8'))
    
    content = result['content'][0]['text']
    # JSONãƒ–ãƒ­ãƒƒã‚¯ã‚’æŠ½å‡ºï¼ˆ```json ... ``` ã§å›²ã¾ã‚Œã¦ã„ã‚‹å ´åˆï¼‰
    if '```json' in content:
        content = content.split('```json')[1].split('```')[0].strip()
    elif '```' in content:
        content = content.split('```')[1].split('```')[0].strip()
    
    return json.loads(content)


def call_gemini(system_prompt: str, user_prompt: str) -> dict:
    """Google Gemini API (AI Studio) ã‚’å‘¼ã³å‡ºã™"""
    api_key = os.environ.get('GEMINI_API_KEY', '')
    if not api_key or api_key.startswith('AIzaSy-xxxx'):
        raise ValueError("GEMINI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚.env ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    
    model = os.environ.get('GEMINI_MODEL', 'gemini-2.0-flash').strip()
    # v1beta ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’ä½¿ç”¨ï¼ˆ2.0ç³»ã¯ã“ã‚ŒãŒå®‰å®šï¼‰
    url = f'https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={api_key}'
    
    payload = {
        "contents": [
            {
                "role": "user",
                "parts": [{"text": user_prompt}]
            }
        ],
        "systemInstruction": {
            "parts": [{"text": system_prompt}]
        },
        "generationConfig": {
            "temperature": 0.7,
            "responseMimeType": "application/json"
        }
    }
    
    data = json.dumps(payload).encode('utf-8')
    req = urllib.request.Request(
        url,
        data=data,
        headers={'Content-Type': 'application/json'},
        method='POST'
    )
    
    with urllib.request.urlopen(req, timeout=60) as resp:
        result = json.loads(resp.read().decode('utf-8'))
    
    content = result['candidates'][0]['content']['parts'][0]['text']
    
    # JSONãƒ–ãƒ­ãƒƒã‚¯ã‚’æŠ½å‡ºï¼ˆ```json ... ``` ã§å›²ã¾ã‚Œã¦ã„ã‚‹å ´åˆï¼‰
    if '```json' in content:
        content = content.split('```json')[1].split('```')[0].strip()
    elif '```' in content:
        content = content.split('```')[1].split('```')[0].strip()
    
    return json.loads(content)


def call_groq(system_prompt: str, user_prompt: str) -> dict:
    """Groq API (Llama 3.3 70B) ã‚’å‘¼ã³å‡ºã™"""
    api_key = os.environ.get('GROQ_API_KEY', '')
    if not api_key or api_key.startswith('gsk_xxxx'):
        raise ValueError("GROQ_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚.env ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    
    model = os.environ.get('GROQ_MODEL', 'llama-3.3-70b-versatile')
    
    payload = {
        "model": model,
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        "temperature": 0.7,
        "response_format": {"type": "json_object"}
    }
    
    data = json.dumps(payload).encode('utf-8')
    req = urllib.request.Request(
        'https://api.groq.com/openai/v1/chat/completions',
        data=data,
        headers={
            'Content-Type': 'application/json',
            'Authorization': f'Bearer {api_key}',
            'User-Agent': 'Kizuki-Log/1.0'
        },
        method='POST'
    )
    
    with urllib.request.urlopen(req, timeout=60) as resp:
        result = json.loads(resp.read().decode('utf-8'))
    
    content = result['choices'][0]['message']['content']
    return json.loads(content)


def analyze_journal(week: int, log_achieved: str, log_unachieved: str,
                    previous_triggers: str = "", instructor_notes: str = "") -> dict:
    """
    ãƒ¡ã‚¤ãƒ³ã®è§£æé–¢æ•°ã€‚
    Constitution Â§5.2 æº–æ‹ ã®JSON ã‚’è¿”ã™ã€‚
    """
    load_env()
    
    provider = os.environ.get('AI_PROVIDER', 'gemini').lower()
    user_prompt = build_user_prompt(week, log_achieved, log_unachieved,
                                    previous_triggers, instructor_notes)
    
    # ãƒ—ãƒ­ãƒã‚¤ãƒ€ â†’ å‘¼ã³å‡ºã—é–¢æ•°ã®ãƒãƒƒãƒ”ãƒ³ã‚°
    provider_map = {
        'gemini': call_gemini,
        'openai': call_openai,
        'anthropic': call_anthropic,
        'groq': call_groq,
    }
    
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨­å®šï¼ˆãƒ¡ã‚¤ãƒ³ãŒ429ã‚¨ãƒ©ãƒ¼ã®å ´åˆã«ä½¿ç”¨ï¼‰
    fallback_provider = os.environ.get('AI_FALLBACK_PROVIDER', '').lower()
    
    try:
        call_fn = provider_map.get(provider, call_gemini)
        try:
            result = call_fn(SYSTEM_PROMPT, user_prompt)
        except urllib.error.HTTPError as e:
            if e.code == 429 and fallback_provider and fallback_provider in provider_map:
                print(f"âš ï¸  {provider} ãŒã‚¯ã‚©ãƒ¼ã‚¿åˆ¶é™ä¸­ã€‚{fallback_provider} ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã™...")
                fallback_fn = provider_map[fallback_provider]
                result = fallback_fn(SYSTEM_PROMPT, user_prompt)
            else:
                raise
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®æ¤œè¨¼
        if 'sos_alert' in result:
            return result  # SOS ã‚¢ãƒ©ãƒ¼ãƒˆã¯ãã®ã¾ã¾è¿”ã™
        
        # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯
        required_keys = ['translation_for_instructor', 'mentoring_support', 'mentoring_seeds']
        for key in required_keys:
            if key not in result:
                raise ValueError(f"APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ '{key}' ãŒã‚ã‚Šã¾ã›ã‚“")
        
        return result
        
    except urllib.error.HTTPError as e:
        error_body = e.read().decode('utf-8') if e.fp else ''
        return {
            "error": True,
            "message": f"API ã‚¨ãƒ©ãƒ¼ ({e.code}): {error_body[:200]}",
            "suggestion": "APIã‚­ãƒ¼ã®è¨­å®šã¨æ®‹é«˜ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
        }
    except urllib.error.URLError as e:
        return {
            "error": True,
            "message": f"æ¥ç¶šã‚¨ãƒ©ãƒ¼: {str(e.reason)}",
            "suggestion": "ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
        }
    except json.JSONDecodeError as e:
        return {
            "error": True,
            "message": f"JSONè§£æã‚¨ãƒ©ãƒ¼: {str(e)}",
            "suggestion": "AIã®å¿œç­”å½¢å¼ãŒä¸æ­£ã§ã—ãŸã€‚å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚"
        }
    except Exception as e:
        return {
            "error": True,
            "message": f"äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {str(e)}",
            "suggestion": "é–‹ç™ºè€…ã«é€£çµ¡ã—ã¦ãã ã•ã„ã€‚"
        }


def analyze_weekly(week_number: int, journals: list) -> dict:
    """
    1é€±é–“åˆ†ã®æ—¥èªŒãƒªã‚¹ãƒˆã‚’åˆ†æã—ã€é€±æ¬¡ãƒ¬ãƒ“ãƒ¥ãƒ¼ã¨ã‚¹ã‚³ã‚¢ã‚’è¿”ã™ã€‚
    journals: [ { "date": "...", "practical_content": "...", "step0_judgments": [...] }, ... ]
    """
    load_env()
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ§‹ç¯‰
    journal_texts = []
    judgments_summary = []
    
    for j in journals:
        date = j.get('date', 'ä¸æ˜')
        content = j.get('practical_content', '')
        unachieved = j.get('unachieved_point', '')
        notes = j.get('instructor_notes', '')
        
        entry = f"--- æ—¥ä»˜: {date} ---\n[å®Ÿç¿’å†…å®¹]\n{content}\n[åçœ]\n{unachieved}\n[æŒ‡å°è€…ãƒ¡ãƒ¢]\n{notes}\n"
        
        juds = j.get('step0_judgments', [])
        if juds:
            entry += "[ç¢ºå®šåˆ¤å®š]\n"
            for jud in juds:
                entry += f"  - Lv.{jud.get('level')} | {jud.get('concept_source')} | {jud.get('evidence')}\n"
        
        journal_texts.append(entry)

    user_prompt = f"""ã€é‡è¦äº‹é …ã€‘
ã“ã‚Œã¯å…¨11é€±é–“ã«ã‚ãŸã‚‹è–¬å±€å®Ÿç¿’ã®ã†ã¡ã€ã€Œç¬¬ {week_number} é€±ç›®ã€ã®ã¾ã¨ã‚åˆ†æã§ã™ã€‚
({week_number}/11é€±ç›®ã¨ã„ã†ç¾åœ¨åœ°ã‚’å¼·ãæ„è­˜ã—ã¦ãã ã•ã„ã€‚åºç›¤ãƒ»ä¸­ç›¤ã®é€±ã§ã‚ã‚‹å ´åˆã€ã€Œå®Ÿç¿’å…¨ä½“ã‚’é€šã—ã¦ã€ã‚„ã€Œåˆæ—¥ã‹ã‚‰æœ€çµ‚æ—¥ã§å¤§ããå¤‰åŒ–ã—ãŸã€ã¨ã„ã£ãŸå®Œäº†å½¢ã®è©•ä¾¡ã¯ä¸é©åˆ‡ã§ã™)

ä»¥ä¸‹ã®ç¬¬ {week_number} é€±ç›®ã®å®Ÿç¿’è¨˜éŒ²ã¨åˆ¤å®šãƒ‡ãƒ¼ã‚¿ã‚’ç²¾æŸ»ã—ã€é€±æ¬¡ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š

{"".join(journal_texts)}

---
ä¸Šè¨˜ã‚’å…ƒã«ã€æŒ‡å®šã•ã‚ŒãŸJSONå½¢å¼ã§é€±æ¬¡ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
"""

    provider = os.environ.get('AI_PROVIDER', 'gemini').lower()
    # é€±æ¬¡åˆ†æã¯æ–‡è„ˆãŒé•·ããªã‚‹ãŸã‚ã€å¯èƒ½ã§ã‚ã‚Œã°ã‚ˆã‚Šè³¢ã„ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠï¼ˆã“ã“ã§ã¯å…±é€šã®ä»•çµ„ã¿ã‚’åˆ©ç”¨ï¼‰
    
    provider_map = {
        'gemini': call_gemini,
        'openai': call_openai,
        'anthropic': call_anthropic,
        'groq': call_groq,
    }
    
    fallback_provider = os.environ.get('AI_FALLBACK_PROVIDER', '').lower()
    
    try:
        call_fn = provider_map.get(provider, call_gemini)
        try:
            result = call_fn(WEEKLY_SYSTEM_PROMPT, user_prompt)
        except urllib.error.HTTPError as e:
            if e.code == 429 and fallback_provider and fallback_provider in provider_map:
                print(f"âš ï¸  é€±æ¬¡åˆ†æ: {provider} ãŒã‚¯ã‚©ãƒ¼ã‚¿åˆ¶é™ä¸­ã€‚{fallback_provider} ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã™...")
                fallback_fn = provider_map[fallback_provider]
                result = fallback_fn(WEEKLY_SYSTEM_PROMPT, user_prompt)
            else:
                raise
        
        # æœ€ä½é™ã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
        if 'weekly_review' not in result or 'internal_scores' not in result:
             raise ValueError("é€±æ¬¡ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚")
        
        return result

    except urllib.error.HTTPError as e:
        error_body = e.read().decode('utf-8') if e.fp else ''
        return {
            "error": True,
            "message": f"API ã‚¨ãƒ©ãƒ¼ ({e.code}): {error_body[:200]}",
            "suggestion": "APIã‚¯ã‚©ãƒ¼ã‚¿åˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚ã—ã°ã‚‰ãå¾…ã¤ã‹ã€åˆ¥ãƒ¢ãƒ‡ãƒ«ï¼ˆGroqç­‰ï¼‰ã‚’ãŠè©¦ã—ãã ã•ã„ã€‚"
        }
    except Exception as e:
        return {
            "error": True,
            "message": f"é€±æ¬¡åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}",
            "suggestion": "ãƒ‡ãƒ¼ã‚¿é‡ãŒå¤šã„å ´åˆã€ãƒ—ãƒ­ãƒã‚¤ãƒ€ã®åˆ¶é™ã«é”ã—ãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚"
        }


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CLIãƒ†ã‚¹ãƒˆç”¨
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == '__main__':
    if '--test' in sys.argv:
        print("=== Kizuki-Log AI Bridge ãƒ†ã‚¹ãƒˆ ===")
        load_env()
        print(f"ãƒ—ãƒ­ãƒã‚¤ãƒ€: {os.environ.get('AI_PROVIDER', 'gemini')}")
        
        # ã‚µãƒ³ãƒ—ãƒ«æ—¥èªŒï¼ˆä¸­ï¨‘ã•ã‚“ Week 1 ã®ãƒ‡ãƒ¼ã‚¿ã‚’åŒ¿ååŒ–ï¼‰
        test_result = analyze_journal(
            week=1,
            log_achieved="""æœ¬æ—¥ã¯ã€å—ä»˜æ¥­å‹™ã®æ‹…å½“ã ã£ãŸã®ã§ã€å‡¦æ–¹ç®‹ã‚’æ‚£è€…ã•ã‚“ã‹ã‚‰å—ã‘å–ã‚‹ã€ãƒã‚¤ãƒŠãƒ³ãƒãƒ¼ã‚«ãƒ¼ãƒ‰ã¨ãŠè–¬æ‰‹å¸³ã‚’æŒã£ã¦ã„ã‚‹ã‹ã®ç¢ºèªã‚’ã—ãŸã€‚
OTCã‚’æ¢ã—ã¦ã„ã‚‹æ‚£è€…ã«å¯¾ã—ã¦ã€ã©ã‚“ãªãŠè–¬ã‚’æ¢ã—ã¦ã„ã‚‹ã‹èã„ãŸã€‚ç›®è–¬ã‚’æ¢ã—ã¦ã„ã‚‹ã¨ã®ã“ã¨ã ã£ãŸã®ã§ã€ç›®ã«ç—›ã¿ãŒã‚ã‚‹ã®ã‹ã€ç›®ãŒä¹¾ã„ã¦ã„ã‚‹ã®ã‹ã‚’èã‘ãŸã“ã¨ã¯è‰¯ã‹ã£ãŸã€‚
æœè–¬æŒ‡å°ã‚‚2ä»¶æ‹…å½“ã•ã›ã¦ã‚‚ã‚‰ã£ãŸã€‚ç·Šå¼µã›ãšã€æ‚£è€…ã•ã‚“ã¨ä¼šè©±ãŒã§ããŸã®ã§ã€å¼•ãç¶šãè½ã¡ç€ã„ã¦å–ã‚Šçµ„ã‚“ã§ã„ããŸã„ã€‚
1ä»¶ç›®ã®æ‚£è€…ã•ã‚“ã¯ã€æ™‚é–“ãŒãªã„ã®ã§æ€¥ã„ã§æ¬²ã—ã„ã¨è¿°ã¹ã‚‰ã‚ŒãŸã€‚ã“ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã¯ã€OSCEã§ã¯æƒ³å®šã—ã¦ã„ãªã‹ã£ãŸã®ã§ã€éå¸¸ã«ã‚ˆã„çµŒé¨“ã«ãªã£ãŸã€‚""",
            log_unachieved="""æœè–¬æŒ‡å°ã®æµã‚Œã‚’çš„ç¢ºã«è¦šãˆã¦ã„ãªã‹ã£ãŸã®ã§ã€æœ¬æ—¥ä¸­ã«ç¢ºèªã—ã€æ˜æ—¥ã¯ä»Šæ—¥ã‚ˆã‚Šæˆé•·ã—ãŸã„ã€‚
éå»ã®è–¬æ­´ã‚’ã¿ã¦ã€æ‚£è€…ã•ã‚“ã«ä¼ãˆã‚‹ã¹ãã“ã¨ãŒä»Šã®æ®µéšã§ã¯ã€å…¨ãã‚ã‹ã‚‰ãªã„ã®ã§ã€è§¦ã‚ŒãŸè–¬ã‹ã‚‰å°‘ã—ãšã¤çŸ¥è­˜ã‚’ã¤ã‘ã¦ã„ã‹ãªã‘ã‚Œã°ã¨æ„Ÿã˜ãŸã€‚""",
            previous_triggers="",
            instructor_notes=""
        )
        
        print("\n--- çµæœ ---")
        print(json.dumps(test_result, ensure_ascii=False, indent=2))
    else:
        print("ä½¿ã„æ–¹: python ai_bridge.py --test")
